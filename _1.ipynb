{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuvW4wtg0ZKUSRSCWsZey7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gokul0Krishna/model/blob/master/_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/the precious.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yGd5VBoQlFI2",
        "outputId": "99cb39cf-a050-422b-84ac-e84516c00291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/the precious.zip\n",
            "   creating: the precious/\n",
            "  inflating: the precious/classifier.pth  \n",
            "  inflating: the precious/classifier_state_dict.pth  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/fmodeltest.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Osv4G_CBlq8W",
        "outputId": "3a866a22-bdce-4104-a6af-549ce03c5bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fmodeltest.zip\n",
            "replace test/P6171199_JPG.rf.5f2c7de501bbedda9884c60099ee72f0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import models,transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "6XAI6s-ilJZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "zbnW9ceBlTZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testmodel = torch.load(\"/content/the precious/wtfclassifier.pth\",weights_only=False,map_location=device)"
      ],
      "metadata": {
        "id": "Vwa6-_4ilUQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model feed"
      ],
      "metadata": {
        "id": "mVZA6_Nh63pI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageFilter\n",
        "import numpy as np\n",
        "\n",
        "def deblur_image_pil(pil_img):\n",
        "    \"\"\"\n",
        "    PIL-based deblurring using inverse filtering approximation\n",
        "\n",
        "    Args:\n",
        "        pil_img: PIL.Image object\n",
        "        iterations: Number of sharpening passes (default=5)\n",
        "\n",
        "    Returns:\n",
        "        Deblurred PIL Image\n",
        "    \"\"\"\n",
        "    # Convert to numpy array\n",
        "    img_array = np.array(pil_img)\n",
        "\n",
        "    # Simulate a simple inverse filter approach\n",
        "    for _ in range(iterations):\n",
        "        # Edge-preserving sharpening\n",
        "        pil_img = pil_img.filter(ImageFilter.UnsharpMask(\n",
        "            radius=2,\n",
        "            percent=150,\n",
        "            threshold=3\n",
        "        ))\n",
        "\n",
        "        # Alternate with mild noise reduction\n",
        "        pil_img = pil_img.filter(ImageFilter.MedianFilter(size=3))\n",
        "\n",
        "    # Enhanced edge sharpening final pass\n",
        "    return pil_img.filter(ImageFilter.UnsharpMask(\n",
        "        radius=1.5,\n",
        "        percent=200,\n",
        "        threshold=2\n",
        "    ))\n",
        "\n",
        "aug_transforms = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "# image being the image\n",
        "iamg=deblur_image_pil(iamg, iterations=2)#imporves qulity of image edges\n",
        "img=aug_transforms(iamg).unsqueeze(0).to(device)\n",
        "ouptut=loaded_model(img)\n",
        "prob=torch.softmax(ouptut,dim=1)\n",
        "predicted_class = torch.argmax(prob).item()"
      ],
      "metadata": {
        "id": "fP_5xB6x65or"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}